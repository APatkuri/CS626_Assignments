{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcUGkcGqBVkh",
        "outputId": "8e2019fd-960b-4c5b-ecb6-29387dcaf0ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/aditya/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/aditya/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package semcor to /home/aditya/nltk_data...\n",
            "[nltk_data]   Package semcor is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/aditya/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/aditya/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(['punkt', 'wordnet', 'semcor', 'stopwords', 'averaged_perceptron_tagger'])\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import semcor\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from num2words import num2words\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jDHkdaRgmIox"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "W2V = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yDdlSB8ls8dn"
      },
      "outputs": [],
      "source": [
        "EXTRA_SW = [\n",
        "    \"''\",\n",
        "    \"'s\",\n",
        "    \"``\"\n",
        "]\n",
        "\n",
        "SW = stopwords.words(\"english\")\n",
        "SW += [p for p in punctuation]\n",
        "SW += EXTRA_SW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "me_BQR1CFNIV"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X5FEJTwHCKL7"
      },
      "outputs": [],
      "source": [
        "def cosineSimilarity(a, b):\n",
        "    cs = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "    return cs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iGRFnQT2q5pB"
      },
      "outputs": [],
      "source": [
        "def isNumber(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0wXiU_kbhHNK"
      },
      "outputs": [],
      "source": [
        "def n2w(w):\n",
        "    if isNumber(w) and w.lower() != \"infinity\" and w.lower() != \"nan\":\n",
        "        w = num2words(w)\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FNsc0CgC4qiP"
      },
      "outputs": [],
      "source": [
        "def lemmatize(w, tag):\n",
        "    if tag is None:\n",
        "        return lemmatizer.lemmatize(w)\n",
        "    else:\n",
        "        return lemmatizer.lemmatize(w, tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NEBmWMwVuBKU"
      },
      "outputs": [],
      "source": [
        "def clean(tokens):\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    lemmatized = [lemmatize(w, treebank2wn(tag)) for w, tag in tagged]\n",
        "    cleaned = [n2w(w) for w in lemmatized if w.lower() not in SW]\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n3U2-JoBmls2"
      },
      "outputs": [],
      "source": [
        "def getVec(w):\n",
        "    try:\n",
        "        v = W2V[w]\n",
        "        return v\n",
        "    except KeyError:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nkY8QXnBS7Bv"
      },
      "outputs": [],
      "source": [
        "def syn2sense(syn):\n",
        "    s = syn.name()\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fvRoWEzRz0oi"
      },
      "outputs": [],
      "source": [
        "def treebank2wn(ttag):\n",
        "    if ttag.startswith(\"J\"):\n",
        "        return wn.ADJ\n",
        "    elif ttag.startswith(\"V\"):\n",
        "        return wn.VERB\n",
        "    elif ttag.startswith(\"N\"):\n",
        "        return wn.NOUN\n",
        "    elif ttag.startswith(\"R\"):\n",
        "        return wn.ADV\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "swX0ECwZ76up"
      },
      "outputs": [],
      "source": [
        "def sent2vec(tokens):\n",
        "\n",
        "    v = 0\n",
        "    n = 0\n",
        "\n",
        "    for w in tokens:\n",
        "\n",
        "        tkns = word_tokenize(w)\n",
        "\n",
        "        if len(tkns) > 1:\n",
        "            for t in tkns:\n",
        "                vt = getVec(t)\n",
        "                if vt is not None:\n",
        "                    n += 1\n",
        "                    v += vt\n",
        "        else:\n",
        "            vw = getVec(w)\n",
        "            if vw is not None:\n",
        "                n += 1\n",
        "                v += vw\n",
        "\n",
        "    if n == 0:\n",
        "        v = None\n",
        "    else:\n",
        "        v /= n\n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U27aDOsWFbdA"
      },
      "outputs": [],
      "source": [
        "def parse(d):\n",
        "\n",
        "    tokens = []\n",
        "    senses = []\n",
        "\n",
        "    for e in d:\n",
        "\n",
        "        if isinstance(e, nltk.tree.Tree):\n",
        "\n",
        "            lemma = e.label()\n",
        "            \n",
        "            if isinstance(lemma, nltk.corpus.reader.wordnet.Lemma):\n",
        "                synset = lemma.synset()\n",
        "                sense = syn2sense(synset)\n",
        "            else:\n",
        "                sense = None\n",
        "            \n",
        "            le = len(e)\n",
        "            if le == 1:\n",
        "                w = e[0]\n",
        "                if isinstance(w, nltk.tree.Tree) or isinstance(w, list):\n",
        "                    lw = len(w)\n",
        "                    w = \" \".join([w[i] for i in range(lw)])\n",
        "            else:\n",
        "                w = \" \".join([e[i] for i in range(le)])\n",
        "\n",
        "        elif isinstance(e, list):\n",
        "            w = e[0]\n",
        "            sense = None\n",
        "\n",
        "        else:\n",
        "            invtype = type(e)\n",
        "            raise TypeError(f\"Invalid type: {invtype}\")\n",
        "\n",
        "        if w:\n",
        "            tokens.append(w)\n",
        "            senses.append(sense)\n",
        "\n",
        "    return tokens, senses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WoJRkwmc_laW"
      },
      "outputs": [],
      "source": [
        "def getCandidates(w, tag):\n",
        "\n",
        "    w = w.replace(\".\", \"\")\n",
        "    w = w.replace(\"-\", \"\")\n",
        "\n",
        "    tkns = word_tokenize(w)\n",
        "    if len(tkns) > 1:\n",
        "        tagged = nltk.pos_tag(tkns)\n",
        "        tags = [treebank2wn(p[1]) for p in tagged]\n",
        "        ltkns = [lemmatize(w, t) for w, t in zip(tkns, tags)]\n",
        "        w = \"_\".join(ltkns)\n",
        "\n",
        "    syns = wn.synsets(w, tag)\n",
        "\n",
        "    if len(syns) == 0:\n",
        "        w = \"_\".join(tkns)\n",
        "        syns = wn.synsets(w, tag)\n",
        "\n",
        "    sense_vectors = []\n",
        "    sense_labels = []\n",
        "\n",
        "    for syn in syns:\n",
        "\n",
        "        label = syn2sense(syn)\n",
        "\n",
        "        defn = syn.definition()\n",
        "\n",
        "        defn = defn.replace(\"_\", \" \")\n",
        "        defn = defn.replace(\"-\", \" \")\n",
        "\n",
        "        tkns = word_tokenize(defn)\n",
        "        if len(tkns) == 0:\n",
        "            raise ValueError(f\"0 tokens found: {defn}\")\n",
        "\n",
        "        clnd = clean(tkns)\n",
        "        if len(clnd) < 2:\n",
        "            clnd = tkns\n",
        "\n",
        "        sv = sent2vec(clnd)\n",
        "\n",
        "        if sv is None:\n",
        "            print(f\"Empty sense vector. Word: {w}, Definition: {defn}, Cleaned: {clnd}. Using a random vector as sense.\")\n",
        "            sv = np.random.rand(300,)\n",
        "        \n",
        "        sense_vectors.append(sv)\n",
        "        sense_labels.append(label)\n",
        "\n",
        "    return sense_vectors, sense_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_yqFveUQDYQD"
      },
      "outputs": [],
      "source": [
        "data = semcor.tagged_sents(tag = \"sem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUegBwQjrUlb",
        "outputId": "61d7a56c-294e-465d-b991-217ef18ff0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 sentences processed\n",
            "Accuracy: 45.0176\n",
            "\n",
            "400 sentences processed\n",
            "Accuracy: 42.1471\n",
            "\n",
            "600 sentences processed\n",
            "Accuracy: 41.3086\n",
            "\n",
            "800 sentences processed\n",
            "Accuracy: 40.3502\n",
            "\n",
            "1000 sentences processed\n",
            "Accuracy: 40.5195\n",
            "\n",
            "1200 sentences processed\n",
            "Accuracy: 40.2166\n",
            "\n",
            "1400 sentences processed\n",
            "Accuracy: 40.2788\n",
            "\n",
            "1600 sentences processed\n",
            "Accuracy: 40.6914\n",
            "\n",
            "1800 sentences processed\n",
            "Accuracy: 40.7218\n",
            "\n",
            "2000 sentences processed\n",
            "Accuracy: 40.6834\n",
            "\n",
            "2200 sentences processed\n",
            "Accuracy: 40.6665\n",
            "\n",
            "Empty context vector. Word: Cancer, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Cancer', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: By no means, Cleaned: ['.'], Tokens: ['By no means', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: For instance, Cleaned: [':'], Tokens: ['For instance', ':']. Using a random vector as context.\n",
            "Empty context vector. Word: Death, Cleaned: ['!'], Tokens: ['Death', '!']. Using a random vector as context.\n",
            "2400 sentences processed\n",
            "Accuracy: 40.9462\n",
            "\n",
            "2600 sentences processed\n",
            "Accuracy: 41.0202\n",
            "\n",
            "2800 sentences processed\n",
            "Accuracy: 41.1394\n",
            "\n",
            "3000 sentences processed\n",
            "Accuracy: 41.5521\n",
            "\n",
            "3200 sentences processed\n",
            "Accuracy: 41.8301\n",
            "\n",
            "3400 sentences processed\n",
            "Accuracy: 42.2804\n",
            "\n",
            "3600 sentences processed\n",
            "Accuracy: 42.7228\n",
            "\n",
            "3800 sentences processed\n",
            "Accuracy: 43.0959\n",
            "\n",
            "4000 sentences processed\n",
            "Accuracy: 43.3105\n",
            "\n",
            "4200 sentences processed\n",
            "Accuracy: 43.7998\n",
            "\n",
            "4400 sentences processed\n",
            "Accuracy: 44.0629\n",
            "\n",
            "4600 sentences processed\n",
            "Accuracy: 43.8796\n",
            "\n",
            "4800 sentences processed\n",
            "Accuracy: 43.8196\n",
            "\n",
            "5000 sentences processed\n",
            "Accuracy: 43.5607\n",
            "\n",
            "5200 sentences processed\n",
            "Accuracy: 43.4199\n",
            "\n",
            "Empty context vector. Word: Therefore, Cleaned: [','], Tokens: ['Therefore', ',']. Using a random vector as context.\n",
            "5400 sentences processed\n",
            "Accuracy: 43.2292\n",
            "\n",
            "5600 sentences processed\n",
            "Accuracy: 43.4266\n",
            "\n",
            "5800 sentences processed\n",
            "Accuracy: 43.2953\n",
            "\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mines, Cleaned: ['.'], Tokens: ['Mines', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Wait, Cleaned: ['``', '!'], Tokens: ['``', 'Wait', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: All right, Cleaned: ['``', '.'], Tokens: ['``', 'All right', '.']. Using a random vector as context.\n",
            "6000 sentences processed\n",
            "Accuracy: 43.1279\n",
            "\n",
            "6200 sentences processed\n",
            "Accuracy: 42.9988\n",
            "\n",
            "Empty context vector. Word: Stevie, Cleaned: ['``', '!'], Tokens: ['``', 'Stevie', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Stevie, Cleaned: [\"''\", '!'], Tokens: ['Stevie', \"''\", '!']. Using a random vector as context.\n",
            "6400 sentences processed\n",
            "Accuracy: 42.9139\n",
            "\n",
            "Empty context vector. Word: Months, Cleaned: ['.'], Tokens: ['Months', '.']. Using a random vector as context.\n",
            "6600 sentences processed\n",
            "Accuracy: 42.8588\n",
            "\n",
            "Empty context vector. Word: Brandon, Cleaned: ['.'], Tokens: ['Brandon', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Johnson, Cleaned: ['.'], Tokens: ['Johnson', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Johnson, Cleaned: ['Sleepy-eyed', 'soft-spoken'], Tokens: ['Sleepy-eyed', ',', 'soft-spoken', 'Johnson', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Knows the score, Cleaned: ['.'], Tokens: ['Knows the score', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Top dog, Cleaned: ['.'], Tokens: ['Top dog', '.']. Using a random vector as context.\n",
            "6800 sentences processed\n",
            "Accuracy: 42.7661\n",
            "\n",
            "7000 sentences processed\n",
            "Accuracy: 42.5828\n",
            "\n",
            "Empty context vector. Word: Eli Corault, Cleaned: ['!'], Tokens: ['Eli Corault', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: John, Cleaned: ['``', '?'], Tokens: ['``', 'John', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Plot, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Plot', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Heretic, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Heretic', \"''\", '!']. Using a random vector as context.\n",
            "7200 sentences processed\n",
            "Accuracy: 42.4456\n",
            "\n",
            "7400 sentences processed\n",
            "Accuracy: 42.4057\n",
            "\n",
            "Empty context vector. Word: Locked, Cleaned: ['.'], Tokens: ['Locked', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Workmen, Cleaned: ['``', '.'], Tokens: ['``', 'Workmen', '.']. Using a random vector as context.\n",
            "7600 sentences processed\n",
            "Accuracy: 42.3601\n",
            "\n",
            "Empty context vector. Word: Tomorrow, Cleaned: ['``', '.'], Tokens: ['``', 'Tomorrow', '.']. Using a random vector as context.\n",
            "7800 sentences processed\n",
            "Accuracy: 42.1965\n",
            "\n",
            "Empty context vector. Word: Warsaw, Cleaned: ['!'], Tokens: ['Warsaw', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Warsaw, Cleaned: ['!'], Tokens: ['Warsaw', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Warsaw, Cleaned: ['!'], Tokens: ['Warsaw', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Miss Rak, Cleaned: ['``', '.'], Tokens: ['``', 'Miss Rak', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Deportees, Cleaned: ['.'], Tokens: ['Deportees', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Jews, Cleaned: ['.'], Tokens: ['Jews', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Captain Androfski, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Captain Androfski', \"''\", '!']. Using a random vector as context.\n",
            "8000 sentences processed\n",
            "Accuracy: 42.1684\n",
            "\n",
            "Empty context vector. Word: Precious, Cleaned: ['``', '.'], Tokens: ['``', 'Precious', '.']. Using a random vector as context.\n",
            "8200 sentences processed\n",
            "Accuracy: 42.0615\n",
            "\n",
            "8400 sentences processed\n",
            "Accuracy: 41.9526\n",
            "\n",
            "Empty context vector. Word: Byron, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Byron', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Beckworth, Cleaned: ['-', '.'], Tokens: ['-', 'Beckworth', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Sir, Cleaned: ['-', '?'], Tokens: ['-', 'Sir', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Exactly, Cleaned: ['!'], Tokens: ['Exactly', '!']. Using a random vector as context.\n",
            "8600 sentences processed\n",
            "Accuracy: 41.9067\n",
            "\n",
            "Empty context vector. Word: Henry, Cleaned: ['-', '?'], Tokens: ['-', 'Henry', '?']. Using a random vector as context.\n",
            "8800 sentences processed\n",
            "Accuracy: 41.8247\n",
            "\n",
            "Empty context vector. Word: Abel, Cleaned: [\"''\", '?'], Tokens: ['Abel', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Pedersen, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Pedersen', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Pedersen, Cleaned: ['.'], Tokens: ['Pedersen', '.']. Using a random vector as context.\n",
            "9000 sentences processed\n",
            "Accuracy: 41.7330\n",
            "\n",
            "Empty context vector. Word: Jorge, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Jorge', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Nothing, Cleaned: ['.'], Tokens: ['Nothing', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'No', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: All right, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'All right', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Shut up, Cleaned: ['``', '.'], Tokens: ['``', 'Shut up', '.']. Using a random vector as context.\n",
            "9200 sentences processed\n",
            "Accuracy: 41.6623\n",
            "\n",
            "Empty context vector. Word: Cousin Ada, Cleaned: ['``', '!'], Tokens: ['``', 'Cousin Ada', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Cousin John, Cleaned: [\"''\", '!'], Tokens: ['Cousin John', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Cousin Lura, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Cousin Lura', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Cousin Howard, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Cousin Howard', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Howard, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Howard', \"''\", '.']. Using a random vector as context.\n",
            "Empty sense vector. Word: ruffle, Definition: discompose, Cleaned: ['discompose']. Using a random vector as sense.\n",
            "Empty context vector. Word: All right, Cleaned: ['``', '.'], Tokens: ['``', 'All right', '.']. Using a random vector as context.\n",
            "9400 sentences processed\n",
            "Accuracy: 41.5213\n",
            "\n",
            "Empty context vector. Word: Leona, Cleaned: [\"''\", '!'], Tokens: ['Leona', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Winston, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Winston', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Picture, Cleaned: ['``', '!'], Tokens: ['``', 'Picture', '!']. Using a random vector as context.\n",
            "9600 sentences processed\n",
            "Accuracy: 41.4355\n",
            "\n",
            "Empty context vector. Word: big chested, Cleaned: ['big-shouldered', 'heavy-armed'], Tokens: ['He', 'be', 'big chested', ',', 'big-shouldered', 'and', 'heavy-armed', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Felix, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Felix', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Felix Grubb, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Felix Grubb', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Felix Grubb, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Felix Grubb', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', '.'], Tokens: ['``', 'No', '.']. Using a random vector as context.\n",
            "9800 sentences processed\n",
            "Accuracy: 41.4170\n",
            "\n",
            "Empty context vector. Word: Reporters, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Reporters', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', '.'], Tokens: ['``', 'No', '.']. Using a random vector as context.\n",
            "10000 sentences processed\n",
            "Accuracy: 41.3604\n",
            "\n",
            "Empty context vector. Word: Hi, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Hi', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Asleep, Cleaned: ['``', '.'], Tokens: ['``', 'Asleep', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Fine, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Fine', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Mike, Cleaned: ['``', '?'], Tokens: ['``', 'Mike', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Yes, Cleaned: ['``', '.'], Tokens: ['``', 'Yes', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Yes, Cleaned: ['``', '.'], Tokens: ['``', 'Yes', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: good, Cleaned: ['impresser', 'Pornsen'], Tokens: ['He', 'be', 'a', 'good', 'impresser', ',', 'that', 'Pornsen', '.']. Using a random vector as context.\n",
            "10200 sentences processed\n",
            "Accuracy: 41.3024\n",
            "\n",
            "Empty context vector. Word: Perhaps, Cleaned: ['.'], Tokens: ['Perhaps', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Pornsen, Cleaned: ['.'], Tokens: ['Pornsen', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Jake Carwood, Cleaned: ['``', '.'], Tokens: ['``', 'Jake Carwood', '.']. Using a random vector as context.\n",
            "10400 sentences processed\n",
            "Accuracy: 41.2848\n",
            "\n",
            "Empty context vector. Word: Judith Pierce, Cleaned: ['.'], Tokens: ['Judith Pierce', '.']. Using a random vector as context.\n",
            "10600 sentences processed\n",
            "Accuracy: 41.2354\n",
            "\n",
            "Empty context vector. Word: Good, Cleaned: ['``', \"''\", '!'], Tokens: ['``', 'Good', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Samples, Cleaned: [':'], Tokens: ['Samples', ':']. Using a random vector as context.\n",
            "10800 sentences processed\n",
            "Accuracy: 41.1611\n",
            "\n",
            "Empty context vector. Word: say, Cleaned: ['Furiouser', 'furiouser'], Tokens: ['``', 'Furiouser', 'and', 'furiouser', \"''\", ',', 'I', 'say', '.']. Using a random vector as context.\n",
            "11000 sentences processed\n",
            "Accuracy: 41.0963\n",
            "\n",
            "Empty context vector. Word: S. J. Perelman, Cleaned: ['.'], Tokens: ['S. J. Perelman', '.']. Using a random vector as context.\n",
            "11200 sentences processed\n",
            "Accuracy: 41.1434\n",
            "\n",
            "Empty context vector. Word: Note, Cleaned: ['(', ':'], Tokens: ['(', 'Note', ':']. Using a random vector as context.\n",
            "11400 sentences processed\n",
            "Accuracy: 41.2412\n",
            "\n",
            "11600 sentences processed\n",
            "Accuracy: 41.3037\n",
            "\n",
            "11800 sentences processed\n",
            "Accuracy: 41.3232\n",
            "\n",
            "12000 sentences processed\n",
            "Accuracy: 41.2976\n",
            "\n",
            "12200 sentences processed\n",
            "Accuracy: 41.3517\n",
            "\n",
            "12400 sentences processed\n",
            "Accuracy: 41.3615\n",
            "\n",
            "12600 sentences processed\n",
            "Accuracy: 41.3449\n",
            "\n",
            "12800 sentences processed\n",
            "Accuracy: 41.4303\n",
            "\n",
            "13000 sentences processed\n",
            "Accuracy: 41.4059\n",
            "\n",
            "13200 sentences processed\n",
            "Accuracy: 41.4080\n",
            "\n",
            "13400 sentences processed\n",
            "Accuracy: 41.4343\n",
            "\n",
            "Empty context vector. Word: No more, Cleaned: ['.'], Tokens: ['No more', '.']. Using a random vector as context.\n",
            "13600 sentences processed\n",
            "Accuracy: 41.3980\n",
            "\n",
            "13800 sentences processed\n",
            "Accuracy: 41.3639\n",
            "\n",
            "14000 sentences processed\n",
            "Accuracy: 41.3704\n",
            "\n",
            "14200 sentences processed\n",
            "Accuracy: 41.3666\n",
            "\n",
            "14400 sentences processed\n",
            "Accuracy: 41.4046\n",
            "\n",
            "14600 sentences processed\n",
            "Accuracy: 41.3517\n",
            "\n",
            "14800 sentences processed\n",
            "Accuracy: 41.3797\n",
            "\n",
            "15000 sentences processed\n",
            "Accuracy: 41.4433\n",
            "\n",
            "Empty context vector. Word: Ventilation, Cleaned: ['.'], Tokens: ['Ventilation', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Lighting, Cleaned: ['.'], Tokens: ['Lighting', '.']. Using a random vector as context.\n",
            "15200 sentences processed\n",
            "Accuracy: 41.4772\n",
            "\n",
            "15400 sentences processed\n",
            "Accuracy: 41.5408\n",
            "\n",
            "15600 sentences processed\n",
            "Accuracy: 41.5879\n",
            "\n",
            "15800 sentences processed\n",
            "Accuracy: 41.6300\n",
            "\n",
            "16000 sentences processed\n",
            "Accuracy: 41.6477\n",
            "\n",
            "16200 sentences processed\n",
            "Accuracy: 41.6437\n",
            "\n",
            "16400 sentences processed\n",
            "Accuracy: 41.6516\n",
            "\n",
            "Empty context vector. Word: Sure, Cleaned: ['.'], Tokens: ['Sure', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Sure, Cleaned: ['.'], Tokens: ['Sure', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Katharine, Cleaned: ['.'], Tokens: ['Katharine', '.']. Using a random vector as context.\n",
            "16600 sentences processed\n",
            "Accuracy: 41.6083\n",
            "\n",
            "Empty context vector. Word: Coffee, Cleaned: ['.'], Tokens: ['Coffee', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Maude, Cleaned: ['?'], Tokens: ['Maude', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Maude, Cleaned: ['.'], Tokens: ['Maude', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Glendora, Cleaned: [\"''\", '-'], Tokens: ['Glendora', \"''\", '-']. Using a random vector as context.\n",
            "Empty context vector. Word: secretary, Cleaned: ['``', 'Gilborn', \"'s\", '?'], Tokens: ['``', 'Gilborn', \"'s\", 'secretary', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Right, Cleaned: ['``', '.'], Tokens: ['``', 'Right', '.']. Using a random vector as context.\n",
            "16800 sentences processed\n",
            "Accuracy: 41.5741\n",
            "\n",
            "Empty context vector. Word: Dad, Cleaned: ['``', '.'], Tokens: ['``', 'Dad', '.']. Using a random vector as context.\n",
            "17000 sentences processed\n",
            "Accuracy: 41.5225\n",
            "\n",
            "Empty context vector. Word: Mae, Cleaned: ['``', \"''\", '-'], Tokens: ['``', 'Mae', \"''\", '-']. Using a random vector as context.\n",
            "17200 sentences processed\n",
            "Accuracy: 41.4970\n",
            "\n",
            "Empty context vector. Word: Motive, Cleaned: ['.'], Tokens: ['Motive', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Right, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Right', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Mullins, Cleaned: ['?'], Tokens: ['Mullins', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Motive, Cleaned: ['?'], Tokens: ['Motive', '?']. Using a random vector as context.\n",
            "17400 sentences processed\n",
            "Accuracy: 41.4699\n",
            "\n",
            "Empty context vector. Word: bequest, Cleaned: ['Ten-thousand-dollar', '.'], Tokens: ['Ten-thousand-dollar', 'bequest', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Impossible, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Impossible', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: office, Cleaned: ['Mahzeer', \"'s\", \"''\", '.'], Tokens: ['Mahzeer', \"'s\", 'office', \"''\", '.']. Using a random vector as context.\n",
            "17600 sentences processed\n",
            "Accuracy: 41.4537\n",
            "\n",
            "Empty context vector. Word: Sir, Cleaned: ['``', '.'], Tokens: ['``', 'Sir', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Jack, Cleaned: [':'], Tokens: ['Jack', ':']. Using a random vector as context.\n",
            "Empty context vector. Word: Casey, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Casey', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Tony Calenda, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Tony Calenda', \"''\", '.']. Using a random vector as context.\n",
            "17800 sentences processed\n",
            "Accuracy: 41.4255\n",
            "\n",
            "Empty context vector. Word: Casey, Cleaned: ['``', '?'], Tokens: ['``', 'Casey', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Tom, Cleaned: ['``', '!'], Tokens: ['``', 'Tom', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Donna, Cleaned: ['!'], Tokens: ['Donna', '!']. Using a random vector as context.\n",
            "18000 sentences processed\n",
            "Accuracy: 41.3977\n",
            "\n",
            "Empty context vector. Word: Five, Cleaned: ['?'], Tokens: ['Five', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Ten, Cleaned: ['?'], Tokens: ['Ten', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Key, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Key', \"''\", '?']. Using a random vector as context.\n",
            "18200 sentences processed\n",
            "Accuracy: 41.3681\n",
            "\n",
            "Empty context vector. Word: Sportin, Cleaned: ['``', \"''\", \"'\", '!'], Tokens: ['``', 'Sportin', \"''\", \"'\", '!']. Using a random vector as context.\n",
            "18400 sentences processed\n",
            "Accuracy: 41.3362\n",
            "\n",
            "Empty context vector. Word: Arbuckle, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Arbuckle', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: No, Cleaned: ['``', '.'], Tokens: ['``', 'No', '.']. Using a random vector as context.\n",
            "18600 sentences processed\n",
            "Accuracy: 41.2742\n",
            "\n",
            "18800 sentences processed\n",
            "Accuracy: 41.2186\n",
            "\n",
            "Empty context vector. Word: Now, Cleaned: ['!'], Tokens: ['Now', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Get in, Cleaned: [\"''\", '.'], Tokens: ['Get in', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: S-s-sahjunt, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'S-s-sahjunt', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Sure, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Sure', \"''\", '.']. Using a random vector as context.\n",
            "19000 sentences processed\n",
            "Accuracy: 41.1731\n",
            "\n",
            "Empty context vector. Word: Splendid, Cleaned: ['``', '.'], Tokens: ['``', 'Splendid', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Murder, Cleaned: ['``', '?'], Tokens: ['``', 'Murder', '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Itch, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Itch', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: Goodbye, Cleaned: ['``', '.'], Tokens: ['``', 'Goodbye', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Softly, Cleaned: ['.'], Tokens: ['Softly', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Warmly, Cleaned: ['.'], Tokens: ['Warmly', '.']. Using a random vector as context.\n",
            "19200 sentences processed\n",
            "Accuracy: 41.1284\n",
            "\n",
            "Empty context vector. Word: Very well, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Very well', \"''\", '.']. Using a random vector as context.\n",
            "19400 sentences processed\n",
            "Accuracy: 41.0839\n",
            "\n",
            "Empty context vector. Word: Osric Pendleton, Cleaned: ['``', \"''\", '?'], Tokens: ['``', 'Osric Pendleton', \"''\", '?']. Using a random vector as context.\n",
            "Empty context vector. Word: laugh, Cleaned: ['Askington', '.'], Tokens: ['Askington', 'laugh', '.']. Using a random vector as context.\n",
            "19600 sentences processed\n",
            "Accuracy: 41.0496\n",
            "\n",
            "Empty context vector. Word: Nothing, Cleaned: ['``', '.'], Tokens: ['``', 'Nothing', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Third, Cleaned: ['``', '!'], Tokens: ['``', 'Third', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Third base, Cleaned: [\"''\", '!'], Tokens: ['Third base', \"''\", '!']. Using a random vector as context.\n",
            "19800 sentences processed\n",
            "Accuracy: 41.0106\n",
            "\n",
            "20000 sentences processed\n",
            "Accuracy: 40.9794\n",
            "\n",
            "20200 sentences processed\n",
            "Accuracy: 40.9407\n",
            "\n",
            "20400 sentences processed\n",
            "Accuracy: 40.8831\n",
            "\n",
            "20600 sentences processed\n",
            "Accuracy: 40.8405\n",
            "\n",
            "20800 sentences processed\n",
            "Accuracy: 40.7946\n",
            "\n",
            "21000 sentences processed\n",
            "Accuracy: 40.7570\n",
            "\n",
            "21200 sentences processed\n",
            "Accuracy: 40.7145\n",
            "\n",
            "21400 sentences processed\n",
            "Accuracy: 40.6878\n",
            "\n",
            "21600 sentences processed\n",
            "Accuracy: 40.6346\n",
            "\n",
            "21800 sentences processed\n",
            "Accuracy: 40.5931\n",
            "\n",
            "22000 sentences processed\n",
            "Accuracy: 40.5621\n",
            "\n",
            "22200 sentences processed\n",
            "Accuracy: 40.5290\n",
            "\n",
            "22400 sentences processed\n",
            "Accuracy: 40.4850\n",
            "\n",
            "22600 sentences processed\n",
            "Accuracy: 40.4428\n",
            "\n",
            "22800 sentences processed\n",
            "Accuracy: 40.3886\n",
            "\n",
            "23000 sentences processed\n",
            "Accuracy: 40.3399\n",
            "\n",
            "23200 sentences processed\n",
            "Accuracy: 40.2963\n",
            "\n",
            "23400 sentences processed\n",
            "Accuracy: 40.2658\n",
            "\n",
            "23600 sentences processed\n",
            "Accuracy: 40.2328\n",
            "\n",
            "23800 sentences processed\n",
            "Accuracy: 40.1871\n",
            "\n",
            "24000 sentences processed\n",
            "Accuracy: 40.1403\n",
            "\n",
            "24200 sentences processed\n",
            "Accuracy: 40.0958\n",
            "\n",
            "24400 sentences processed\n",
            "Accuracy: 40.0459\n",
            "\n",
            "24600 sentences processed\n",
            "Accuracy: 40.0095\n",
            "\n",
            "24800 sentences processed\n",
            "Accuracy: 39.9709\n",
            "\n",
            "25000 sentences processed\n",
            "Accuracy: 39.9267\n",
            "\n",
            "25200 sentences processed\n",
            "Accuracy: 39.8766\n",
            "\n",
            "25400 sentences processed\n",
            "Accuracy: 39.8404\n",
            "\n",
            "Empty context vector. Word: understood, Cleaned: ['Leninism-Marxism', 'Exegete'], Tokens: ['Leninism-Marxism', ',', 'a', 'understood', 'by', 'Exegete', '.']. Using a random vector as context.\n",
            "25600 sentences processed\n",
            "Accuracy: 39.7960\n",
            "\n",
            "25800 sentences processed\n",
            "Accuracy: 39.7571\n",
            "\n",
            "26000 sentences processed\n",
            "Accuracy: 39.7158\n",
            "\n",
            "26200 sentences processed\n",
            "Accuracy: 39.6817\n",
            "\n",
            "26400 sentences processed\n",
            "Accuracy: 39.6420\n",
            "\n",
            "26600 sentences processed\n",
            "Accuracy: 39.5923\n",
            "\n",
            "26800 sentences processed\n",
            "Accuracy: 39.5616\n",
            "\n",
            "27000 sentences processed\n",
            "Accuracy: 39.5221\n",
            "\n",
            "27200 sentences processed\n",
            "Accuracy: 39.4809\n",
            "\n",
            "27400 sentences processed\n",
            "Accuracy: 39.4328\n",
            "\n",
            "27600 sentences processed\n",
            "Accuracy: 39.3855\n",
            "\n",
            "27800 sentences processed\n",
            "Accuracy: 39.3429\n",
            "\n",
            "28000 sentences processed\n",
            "Accuracy: 39.2841\n",
            "\n",
            "28200 sentences processed\n",
            "Accuracy: 39.2503\n",
            "\n",
            "28400 sentences processed\n",
            "Accuracy: 39.2156\n",
            "\n",
            "28600 sentences processed\n",
            "Accuracy: 39.1776\n",
            "\n",
            "28800 sentences processed\n",
            "Accuracy: 39.1352\n",
            "\n",
            "29000 sentences processed\n",
            "Accuracy: 39.1162\n",
            "\n",
            "29200 sentences processed\n",
            "Accuracy: 39.0777\n",
            "\n",
            "29400 sentences processed\n",
            "Accuracy: 39.0466\n",
            "\n",
            "Empty context vector. Word: Simmer, Cleaned: ['15', '.'], Tokens: ['Simmer', '15', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Serves, Cleaned: ['12', '.'], Tokens: ['Serves', '12', '.']. Using a random vector as context.\n",
            "29600 sentences processed\n",
            "Accuracy: 39.0137\n",
            "\n",
            "29800 sentences processed\n",
            "Accuracy: 38.9899\n",
            "\n",
            "30000 sentences processed\n",
            "Accuracy: 38.9623\n",
            "\n",
            "30200 sentences processed\n",
            "Accuracy: 38.9316\n",
            "\n",
            "Empty context vector. Word: Stop, Cleaned: ['``', '!'], Tokens: ['``', 'Stop', '!']. Using a random vector as context.\n",
            "30400 sentences processed\n",
            "Accuracy: 38.9068\n",
            "\n",
            "30600 sentences processed\n",
            "Accuracy: 38.8691\n",
            "\n",
            "30800 sentences processed\n",
            "Accuracy: 38.8383\n",
            "\n",
            "31000 sentences processed\n",
            "Accuracy: 38.8002\n",
            "\n",
            "31200 sentences processed\n",
            "Accuracy: 38.7542\n",
            "\n",
            "Empty sense vector. Word: ruffle, Definition: discompose, Cleaned: ['discompose']. Using a random vector as sense.\n",
            "31400 sentences processed\n",
            "Accuracy: 38.7302\n",
            "\n",
            "31600 sentences processed\n",
            "Accuracy: 38.7030\n",
            "\n",
            "31800 sentences processed\n",
            "Accuracy: 38.6688\n",
            "\n",
            "32000 sentences processed\n",
            "Accuracy: 38.6374\n",
            "\n",
            "32200 sentences processed\n",
            "Accuracy: 38.5967\n",
            "\n",
            "32400 sentences processed\n",
            "Accuracy: 38.5717\n",
            "\n",
            "32600 sentences processed\n",
            "Accuracy: 38.5372\n",
            "\n",
            "32800 sentences processed\n",
            "Accuracy: 38.5083\n",
            "\n",
            "33000 sentences processed\n",
            "Accuracy: 38.4762\n",
            "\n",
            "33200 sentences processed\n",
            "Accuracy: 38.4505\n",
            "\n",
            "33400 sentences processed\n",
            "Accuracy: 38.4022\n",
            "\n",
            "33600 sentences processed\n",
            "Accuracy: 38.3589\n",
            "\n",
            "33800 sentences processed\n",
            "Accuracy: 38.3332\n",
            "\n",
            "34000 sentences processed\n",
            "Accuracy: 38.3127\n",
            "\n",
            "34200 sentences processed\n",
            "Accuracy: 38.2907\n",
            "\n",
            "34400 sentences processed\n",
            "Accuracy: 38.2602\n",
            "\n",
            "Empty context vector. Word: Receiving, Cleaned: ['``', \"''\", '.'], Tokens: ['``', 'Receiving', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: ask, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'ask', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: Take it easy, Cleaned: [\"''\", '.'], Tokens: ['Take it easy', \"''\", '.']. Using a random vector as context.\n",
            "Empty context vector. Word: suggest, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'suggest', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: stood up, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'stood up', '.']. Using a random vector as context.\n",
            "34600 sentences processed\n",
            "Accuracy: 38.2392\n",
            "\n",
            "Empty context vector. Word: demand, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'demand', '.']. Using a random vector as context.\n",
            "Empty context vector. Word: scowl, Cleaned: ['Ekstrohm', '.'], Tokens: ['Ekstrohm', 'scowl', '.']. Using a random vector as context.\n",
            "34800 sentences processed\n",
            "Accuracy: 38.2209\n",
            "\n",
            "Empty context vector. Word: Get up, Cleaned: ['``', '.'], Tokens: ['``', 'Get up', '.']. Using a random vector as context.\n",
            "35000 sentences processed\n",
            "Accuracy: 38.1884\n",
            "\n",
            "35200 sentences processed\n",
            "Accuracy: 38.1695\n",
            "\n",
            "35400 sentences processed\n",
            "Accuracy: 38.1478\n",
            "\n",
            "Empty context vector. Word: Hurry, Cleaned: ['``', '!'], Tokens: ['``', 'Hurry', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Hurry, Cleaned: [\"''\", '!'], Tokens: ['Hurry', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Hustle, Cleaned: [\"''\", '!'], Tokens: ['Hustle', \"''\", '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Fort up, Cleaned: ['!'], Tokens: ['Fort up', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Lead up, Cleaned: ['``', '!'], Tokens: ['``', 'Lead up', '!']. Using a random vector as context.\n",
            "Empty context vector. Word: Lead up, Cleaned: ['!'], Tokens: ['Lead up', '!']. Using a random vector as context.\n",
            "35600 sentences processed\n",
            "Accuracy: 38.1266\n",
            "\n",
            "35800 sentences processed\n",
            "Accuracy: 38.1029\n",
            "\n",
            "36000 sentences processed\n",
            "Accuracy: 38.0739\n",
            "\n",
            "36200 sentences processed\n",
            "Accuracy: 38.0445\n",
            "\n",
            "36400 sentences processed\n",
            "Accuracy: 38.0087\n",
            "\n",
            "Empty context vector. Word: Take off, Cleaned: ['``', ',', 'fly-boy', \"''\", '!'], Tokens: ['``', 'Take off', ',', 'fly-boy', \"''\", '!']. Using a random vector as context.\n",
            "36600 sentences processed\n",
            "Accuracy: 37.9723\n",
            "\n",
            "36800 sentences processed\n",
            "Accuracy: 37.9478\n",
            "\n",
            "37000 sentences processed\n",
            "Accuracy: 37.9246\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_total = 0\n",
        "n_correct = 0\n",
        "n_samples = 0\n",
        "\n",
        "true = []\n",
        "pred = []\n",
        "\n",
        "for d in data:\n",
        "\n",
        "    try:\n",
        "\n",
        "        tokens, senses = parse(d)\n",
        "        n_tokens = len(tokens)\n",
        "\n",
        "        tagged = nltk.pos_tag(tokens)\n",
        "        tags = [treebank2wn(p[1]) for p in tagged]\n",
        "        tokens = [lemmatize(w, tag) for w, tag in zip(tokens, tags)]\n",
        "\n",
        "        for i in range(n_tokens):\n",
        "\n",
        "            w = tokens[i]\n",
        "            tag = tags[i]\n",
        "            s_true = senses[i]\n",
        "\n",
        "            if not isinstance(w, str):\n",
        "                raise TypeError(f\"Invalid type: {type(w)} : {w} : {tokens}\")\n",
        "\n",
        "            if s_true is None:\n",
        "                continue\n",
        "\n",
        "            context = tokens.copy()\n",
        "            del context[i]\n",
        "\n",
        "            cleaned = clean(context)\n",
        "            if len(cleaned) < 2:\n",
        "                cleaned = context\n",
        "                \n",
        "            cv = sent2vec(cleaned)\n",
        "\n",
        "            if cv is None:\n",
        "                print(f\"Empty context vector. Word: {w}, Cleaned: {cleaned}, Tokens: {tokens}. Using a random vector as context.\")\n",
        "                cv = np.random.rand(300,)\n",
        "\n",
        "            sense_vectors, sense_labels = getCandidates(w, tag)\n",
        "            n_candidates = len(sense_labels)\n",
        "\n",
        "            s_pred = None\n",
        "            if n_candidates == 0:\n",
        "                sense_vectors, sense_labels = getCandidates(w, None)\n",
        "                n_candidates = len(sense_labels)\n",
        "                if n_candidates == 0:\n",
        "                    s_pred = random.choice([\"group.n.01\", \"person.n.01\", \"location.n.01\"])\n",
        "            \n",
        "            best = -1 \n",
        "            for j in range(n_candidates):\n",
        "                sv = sense_vectors[j]\n",
        "                cs = cosineSimilarity(cv, sv)\n",
        "                if cs > best:\n",
        "                    best = cs\n",
        "                    s_pred = sense_labels[j]\n",
        "\n",
        "            if s_true == s_pred:\n",
        "                n_correct += 1\n",
        "            n_total += 1\n",
        "\n",
        "            true.append(s_true)\n",
        "            pred.append(s_pred)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error at: {n_samples}\")\n",
        "        print(str(e))\n",
        "        raise ValueError(\"Error\")\n",
        "\n",
        "    n_samples += 1\n",
        "\n",
        "    if n_samples%200 == 0:\n",
        "        print(f\"{n_samples} sentences processed\")\n",
        "        acc = (n_correct/n_total)*100\n",
        "        print(f\"Accuracy: {acc:.4f}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0yKCvj0mcu_1"
      },
      "outputs": [],
      "source": [
        "pred_sense_set = set(pred)\n",
        "true_sense_set = set(true)\n",
        "all_senses = sorted(list(true_sense_set.union(pred_sense_set)))\n",
        "not_predicted = true_sense_set - pred_sense_set\n",
        "extra_predicted = pred_sense_set - true_sense_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS2imPibGSEe",
        "outputId": "a1fe36e2-3cdd-4960-da10-a3edf3a271c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aditya/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/aditya/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3789\n",
            "Precision: 0.4133\n",
            "Recall: 0.4007\n",
            "F1-Score: 0.3773\n"
          ]
        }
      ],
      "source": [
        "acc = accuracy_score(true, pred)\n",
        "prec = precision_score(true, pred, average = \"macro\")\n",
        "rec = recall_score(true, pred, average = \"macro\")\n",
        "f1 = f1_score(true, pred, average = \"macro\")\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {rec:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Bsb2D-5bfxE7"
      },
      "outputs": [],
      "source": [
        "def predict(sent):\n",
        "\n",
        "    senses = []\n",
        "    tokens = word_tokenize(sent)\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    tags = [treebank2wn(p[1]) for p in tagged]\n",
        "    tokens = [lemmatize(w, tag) for w, tag in zip(tokens, tags)]\n",
        "    n_tokens = len(tokens)\n",
        "\n",
        "    for i in range(n_tokens):\n",
        "\n",
        "        w = tokens[i]\n",
        "        tag = tags[i]\n",
        "\n",
        "        context = tokens.copy()\n",
        "        del context[i]\n",
        "\n",
        "        cv = sent2vec(context)\n",
        "\n",
        "        if cv is None:\n",
        "            print(f\"Empty context vector. Word: {w}, Tokens: {tokens}. Using a random vector as context.\")\n",
        "            cv = np.random.rand(300,)\n",
        "\n",
        "        sense_vectors, sense_labels = getCandidates(w, tag)\n",
        "        n_candidates = len(sense_labels)\n",
        "\n",
        "        s_pred = None\n",
        "        if n_candidates == 0:\n",
        "            sense_vectors, sense_labels = getCandidates(w, None)\n",
        "            n_candidates = len(sense_labels)\n",
        "            if n_candidates == 0:\n",
        "                print(f\"No synsets found: {w}\")\n",
        "                s_pred = None\n",
        "\n",
        "        best = -1 \n",
        "        for j in range(n_candidates):\n",
        "            sv = sense_vectors[j]\n",
        "            cs = cosineSimilarity(cv, sv)\n",
        "            if cs > best:\n",
        "                best = cs\n",
        "                s_pred = sense_labels[j]\n",
        "\n",
        "        senses.append(s_pred)\n",
        "\n",
        "    return senses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez6y5gsegqYt",
        "outputId": "bc1e4616-7270-4d8d-ca76-b0e4ebc3680b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No synsets found: of\n",
            "No synsets found: we\n",
            "on.r.03 : in a state required for something to function or be effective\n",
            "combustion.n.01 : a process in which a substance reacts with oxygen to give heat and light\n",
            "ember.n.01 : a hot fragment of wood or coal that is left from a fire and is glowing or smoldering\n",
            "get.v.01 : come into the possession of something concrete or abstract\n",
            "ash.n.01 : the residue that remains when something is burned\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sents = [\n",
        "    \"On combustion of coal we get ash\", \n",
        " ]\n",
        "\n",
        "for sent in sents:\n",
        "    senses = predict(sent)\n",
        "    for s in senses:\n",
        "        if s is not None:\n",
        "            print(s, \":\", wn.synset(s).definition())\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS626-A2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
